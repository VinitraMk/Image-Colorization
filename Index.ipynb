{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"tz4GjH2tQCVy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721668797641,"user_tz":240,"elapsed":23794,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}},"outputId":"28ca3409-3215-4c09-c79a-bfb1c6eb6958"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","drive  sample_data\n"]}],"source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!ls"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":450,"status":"ok","timestamp":1721668798076,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"},"user_tz":240},"id":"IJYf-GAtQzLp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9bfd5fea-cc42-4fe4-b118-5020e540a5ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Personal-Projects/Image-Colorization\n","common\t     datautils\t  Index.ipynb  output\t\t\t README.md\n","config.yaml  experiments  index.py     preprocess_imagenette.py  requirements.txt\n","data\t     Index_bc.py  models       project-structure.md\t run.yaml\n"]}],"source":["# move into project directory\n","repo_name = \"Image-Colorization\"\n","%cd /content/drive/MyDrive/Personal-Projects/$repo_name\n","!ls"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1721668798078,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"},"user_tz":240},"id":"rnSym0W0Rmz-","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"ebd03462-61bc-4fba-f99f-c5dc4baa4b3f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\\n!pip install matplotlib numpy pandas pyyaml opencv-python\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["# set up environment\n","# comment out if not required\n","'''\n","!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install matplotlib numpy pandas pyyaml opencv-python\n","'''"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VvSx-iP1P0Rx","executionInfo":{"status":"ok","timestamp":1721668798080,"user_tz":240,"elapsed":15,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["# this cell is for downloading data.\n","# as of yet data is not hosted and is available in the private data folder\n","#!tar -xvzf data/imagenette2-320.tgz\n","#!unzip -qq data/imagenette2-320-processed.zip -d data/\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"BboU3GhFP0R1","executionInfo":{"status":"ok","timestamp":1721668816686,"user_tz":240,"elapsed":18620,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["# setup some imports\n","#custom imports\n","from common.transforms import ToTensor\n","from datautils.datareader import DataReader\n","from datautils.datareader import ImagenetteReader\n","from datautils.dataset import CustomDataset\n","from datautils.dataset import CustomImagenetDataset\n","from common.utils import get_exp_params, init_config, get_config, save2config, get_saved_model, get_modelinfo, get_model_data\n","from models.unet import UNet\n","from models.conv_net import ConvNet\n","from models.custom_models import get_model\n","\n","#py imports\n","import random\n","import numpy as np\n","import os\n","import torch\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from experiments.experiments import Experiment\n","from common.visualization import Visualization\n","from experiments.test_model import ModelTester"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":922,"status":"ok","timestamp":1721668817581,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"},"user_tz":240},"id":"NkWvKW0NP0R3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a8fe50d0-be2a-4251-e66a-39c9ccdfe442"},"outputs":[{"output_type":"stream","name":"stdout","text":["Config parameters\n","\n","{'X_key': 'L', 'data_dir': '/content/drive/MyDrive/Personal-Projects/Image-Colorization/data', 'device': 'cuda', 'output_dir': '/content/drive/MyDrive/Personal-Projects/Image-Colorization/output', 'root_dir': '/content/drive/MyDrive/Personal-Projects/Image-Colorization', 'use_gpu': True, 'y_key': 'AB'}\n"]}],"source":["# initialize directories and config data\n","init_config()\n","config = get_config()\n","print('Config parameters\\n')\n","print(config)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":387,"status":"ok","timestamp":1721668817963,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"},"user_tz":240},"id":"U3VbVcUUP0R2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"195f6dfa-4b22-4a97-acd3-a26d1cbee171"},"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment parameters\n","\n","{'transform': {'resize_dim': 256, 'crop_dim': 224}, 'train': {'shuffle_data': True, 'batch_size': 32, 'val_split_method': 'fixed-split', 'k': 3, 'val_percentage': 20, 'loss': 'l1', 'epoch_interval': 5, 'num_epochs': 1500}, 'model': {'name': 'conv_net', 'optimizer': 'Adam', 'lr': 0.0001, 'weight_decay': 1e-07, 'amsgrad': True, 'momentum': 0.8, 'build_on_pretrained': False, 'pretrained_filename': '/models/checkpoints/last_model.pt'}, 'dataset': {'name': 'imagenette', 'size': 'full'}}\n"]}],"source":["# read experiment parameters\n","exp_params = get_exp_params()\n","print('Experiment parameters\\n')\n","print(exp_params)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"moZyTdJtP0R4","executionInfo":{"status":"ok","timestamp":1721668817963,"user_tz":240,"elapsed":4,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["#initialize randomness seed\n","seed = 123\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":51385,"status":"ok","timestamp":1721668869345,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"},"user_tz":240},"id":"hyMh9b7qP0R4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6741a1bd-9d35-4807-d396-75f8f792ee8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Full train dataset length: 9469\n","Test dataset length: 3925\n","Subset train dataset length: 94\n","Subset test dataset length: 39 \n","\n"]}],"source":["# read and load custom data\n","\n","#save X_key and y_key\n","save2config('X_key', 'L')\n","save2config('y_key', 'AB')\n","\n","if exp_params['dataset']['name'] == 'custom':\n","    #preprocess data or load preprocessed data (custom)\n","    dr = DataReader()\n","    ds = dr.get_split_data()\n","    Ltr, ABtr, ftr_len = ds['Ltr'], ds['ABtr'], ds['ftr_len']\n","    Lte, ABte, te_len = ds['Lte'], ds['ABte'], ds['te_len']\n","    print('Shape of X and y:', ds['Ltr'].shape, ds['ABtr'].shape)\n","\n","    #transform data\n","    composed_transforms =  transforms.Compose([\n","        ToTensor()\n","    ])\n","    #convert to dataset\n","    ftr_dataset = CustomDataset(Ltr, ABtr, ftr_len)\n","    te_dataset = CustomDataset(Lte, ABte, te_len)\n","    smlen = int(0.01 * len(ftr_dataset))\n","    smftr_dataset = torch.utils.data.Subset(ftr_dataset, list(range(smlen)))\n","    smftrte_dataset = torch.utils.data.Subset(ftr_dataset, list(range(10)))\n","    smtelen = int(0.1 * len(te_dataset))\n","    smfte_dataset = torch.utils.data.Subset(te_dataset, list(range(smtelen)))\n","    print('Full train dataset length:', len(ftr_dataset))\n","    print('Test dataset length:', len(te_dataset))\n","    print('Subset train dataset length:', smlen)\n","    print('Subset test dataset length:', smtelen, '\\n')\n","elif exp_params['dataset']['name'] == 'imagenette':\n","    dr = ImagenetteReader()\n","    train_paths, test_paths = dr.get_data_filepaths()\n","    ftr_dataset = CustomImagenetDataset(train_paths)\n","    te_dataset = CustomImagenetDataset(test_paths)\n","    smlen = int(0.01 * len(ftr_dataset))\n","    smftr_dataset = torch.utils.data.Subset(ftr_dataset, list(range(smlen)))\n","    smtelen = int(0.01 * len(te_dataset))\n","    smfte_dataset = torch.utils.data.Subset(te_dataset, list(range(smtelen)))\n","    smftrte_dataset = torch.utils.data.Subset(smftr_dataset, list(range(10)))\n","    print('Full train dataset length:', len(ftr_dataset))\n","    print('Test dataset length:', len(te_dataset))\n","    print('Subset train dataset length:', smlen)\n","    print('Subset test dataset length:', smtelen, '\\n')\n","else:\n","    raise SystemError('Invalid dataset name passed!')\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"7YhIO8ZtFKuK","colab":{"base_uri":"https://localhost:8080/","height":738},"outputId":"20087053-9869-4625-b12b-b967d58a1c90","executionInfo":{"status":"error","timestamp":1721681760439,"user_tz":240,"elapsed":6361952,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Running straight split\n","Loading saved model\n","\tRunning Epoch 743\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\t\tRunning through training set: 100%|██████████| 237/237 [16:30<00:00,  4.18s/it]\n","\t\tRunning through validation set: 100%|██████████| 60/60 [01:09<00:00,  1.15s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\tEpoch 743 Training Loss: 0.04835337879964265\n","\tEpoch 743 Validation Loss: 0.06770645777069571\n","\tRunning Epoch 745\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\t\tRunning through training set: 100%|██████████| 237/237 [12:28<00:00,  3.16s/it]\n","\t\tRunning through validation set: 100%|██████████| 60/60 [01:08<00:00,  1.14s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\tEpoch 745 Training Loss: 0.04826877570249841\n","\tEpoch 745 Validation Loss: 0.07018919764170241\n","\tRunning Epoch 750\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 237/237 [12:32<00:00,  3.17s/it]\n","\t\tRunning through validation set: 100%|██████████| 60/60 [01:08<00:00,  1.15s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 750 Training Loss: 0.04799415298600887\n","\tEpoch 750 Validation Loss: 0.06397283070942617\n","\tRunning Epoch 755\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 237/237 [12:35<00:00,  3.19s/it]\n","\t\tRunning through validation set: 100%|██████████| 60/60 [01:08<00:00,  1.14s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 755 Training Loss: 0.04900725235830139\n","\tEpoch 755 Validation Loss: 0.07359492558763572\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-b841e49e9c24>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         ])\n\u001b[1;32m     33\u001b[0m         \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mftr_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomposed_transforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'imagenette'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid dataset name passed!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Personal-Projects/Image-Colorization/experiments/experiments.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m             )\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mls\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 model, model_info = self.__conduct_training(model, -1, epoch_index,\n\u001b[0m\u001b[1;32m    222\u001b[0m                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0mtr_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Personal-Projects/Image-Colorization/experiments/experiments.py\u001b[0m in \u001b[0;36m__conduct_training\u001b[0;34m(self, model, fold_idx, epoch_index, train_loader, val_loader, train_len, val_len, trlosshistory, vallosshistory, valerrhistory)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;31m#torch.cuda.empty_cache()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                             )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 state_steps)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    319\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_addcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_exp_avgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_state_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m             \u001b[0mbias_correction2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_state_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_addcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_exp_avgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_state_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m             \u001b[0mbias_correction2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_state_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_stack_if_compiling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# model training\n","\n","if exp_params['dataset']['name'] == 'custom':\n","    if exp_params['dataset']['size'] == 'subset':\n","        #model training with small dataset (custom)\n","        exp = Experiment(exp_params[\"model\"][\"name\"], smftr_dataset)\n","        model_history = exp.train()\n","    else:\n","        #model training with full dataset (custom)\n","        exp = Experiment(exp_params[\"model\"][\"name\"], ftr_dataset)\n","        model_history = exp.train()\n","elif exp_params['dataset']['name'] == 'imagenette':\n","    if exp_params['dataset']['size'] == 'subset':\n","        #model training with small dataset (imagenette)\n","        composed_transforms =  transforms.Compose([\n","            #transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                        std=[0.229, 0.224, 0.225]),\n","            transforms.Resize(exp_params['transform']['resize_dim']),\n","            transforms.CenterCrop(exp_params['transform']['crop_dim'])\n","        ])\n","        exp = Experiment(exp_params[\"model\"][\"name\"], smftr_dataset, composed_transforms, 'imagenette')\n","        model_history = exp.train()\n","    else:\n","        #model training with full dataset (imagenette)\n","        composed_transforms =  transforms.Compose([\n","            #transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                        std=[0.229, 0.224, 0.225]),\n","            transforms.Resize(exp_params['transform']['resize_dim']),\n","            transforms.CenterCrop(exp_params['transform']['crop_dim'])\n","        ])\n","        exp = Experiment(exp_params[\"model\"][\"name\"], ftr_dataset, composed_transforms, 'imagenette')\n","        model_history = exp.train()\n","else:\n","    raise SystemError('Invalid dataset name passed!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZyTPPFH8FWOZ","executionInfo":{"status":"aborted","timestamp":1721681760442,"user_tz":240,"elapsed":4,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["# test model on validation set\n","\n","if exp_params['dataset']['name'] == 'custom' or exp_params['dataset']['name'] == 'imagenette':\n","    # get best model with custom dataset\n","    model, model_history, _ = get_model_data(exp_params[\"model\"][\"name\"])\n","    #model = get_saved_model(model, '')\n","    model_info = get_modelinfo('')\n","    print(\"\\nModel validation results\")\n","    #visualization results\n","    vis = Visualization(model_info, model_history)\n","    vis.get_results()\n","else:\n","    raise SystemError('Invalid dataset name passed!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G1Qr1SVCRuHh","executionInfo":{"status":"aborted","timestamp":1721681760446,"user_tz":240,"elapsed":8,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["# test fine-tuned model on training set\n","\n","if exp_params['dataset']['name'] == 'custom':\n","    #model testing with small subset of training dataset\n","    model = get_model(exp_params[\"model\"][\"name\"])\n","    model.load_state_dict(torch.load(\"models/checkpoints/last_model.pt\", map_location = torch.device(config[\"device\"])))\n","    print(\"\\n\\nTesting Saved Model on Training set subset\")\n","    mt = ModelTester(model, smftrte_dataset)\n","    mt.test_and_plot(ds[\"RGBtr\"], ABtr, \"best_model\", True)\n","elif exp_params['dataset']['name'] == 'imagenette':\n","    #model testing with small subset of training dataset (imagenette)\n","    composed_transforms =  transforms.Compose([\n","            #transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                        std=[0.229, 0.224, 0.225]),\n","            transforms.Resize(exp_params['transform']['resize_dim']),\n","            transforms.CenterCrop(exp_params['transform']['crop_dim'])\n","        ])\n","    model = get_model(exp_params[\"model\"][\"name\"])\n","    model.load_state_dict(torch.load(\"models/checkpoints/last_model.pt\", map_location = torch.device(config[\"device\"])))\n","    print(\"\\n\\nTesting Saved Model on subset of training set\")\n","    mt = ModelTester(model, smftrte_dataset, composed_transforms)\n","    mt.test_imagenette_and_plot(True)\n","else:\n","    raise SystemError('Invalid dataset name passed!')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPqmws5k2gD9","executionInfo":{"status":"aborted","timestamp":1721681760449,"user_tz":240,"elapsed":11,"user":{"displayName":"VinitraMk","userId":"14045597532953840063"}}},"outputs":[],"source":["'''\n","# test fine-tuned model on test set\n","if exp_params['dataset']['name'] == 'custom':\n","    # model testing with small subset of training dataset\n","    model = get_model(exp_params[\"model\"][\"name\"])\n","    model.load_state_dict(torch.load(\"models/checkpoints/last_model.pt\", map_location = torch.device(config[\"device\"])))\n","    if exp_params['dataset']['size'] == 'subset':\n","        print(\"\\n\\nTesting Saved Model subset of test set\")\n","        mt = ModelTester(model, smfte_dataset)\n","        mt.test_and_plot(ds[\"RGBte\"], ABte, \"best_model\", True)\n","    else:\n","        print(\"\\n\\nTesting Saved Model on full test set\")\n","        mt = ModelTester(model, te_dataset)\n","        mt.test_and_plot(ds[\"RGBte\"], ABte, \"best_model\", True)\n","elif exp_params['dataset']['name'] == 'imagenette':\n","    # model testing with small subset of training dataset (imagenette)\n","    model = get_model(exp_params[\"model\"][\"name\"])\n","    model.load_state_dict(torch.load(\"models/checkpoints/last_model.pt\", map_location = torch.device(config[\"device\"])))\n","    if exp_params['dataset']['size'] == 'subset':\n","        print(\"\\n\\nTesting Saved Model on subset of test set\")\n","        mt = ModelTester(model, smfte_dataset, composed_transforms)\n","        mt.test_imagenette_and_plot(True)\n","    else:\n","        print(\"\\n\\nTesting Saved Model on full test set\")\n","        mt = ModelTester(model, te_dataset, composed_transforms)\n","        mt.test_imagenette_and_plot(True)\n","else:\n","    raise SystemError('Invalid dataset name passed!')\n","'''"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}