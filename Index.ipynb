{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1817,"status":"ok","timestamp":1719456194610,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"tz4GjH2tQCVy","outputId":"56e5f8f9-223e-42d8-8333-8c8f57949772"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","drive  sample_data\n"]}],"source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!ls"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1719456194611,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"IJYf-GAtQzLp","outputId":"13e5c7ae-3fe7-4ef1-c859-8906b9019029"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Personal-Projects/Image-Colorization\n","common\t     datautils\t  Index.ipynb  output\t\t\t README.md\n","config.yaml  experiments  index.py     preprocess_imagenette.py  requirements.txt\n","data\t     Index_bc.py  models       project-structure.md\t run.yaml\n"]}],"source":["# move into project directory\n","repo_name = \"Image-Colorization\"\n","%cd /content/drive/MyDrive/Personal-Projects/$repo_name\n","!ls"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1719456194612,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"rnSym0W0Rmz-","outputId":"20e59b3c-8216-47a0-9c29-0962603a6394"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\\n!pip install matplotlib numpy pandas pyyaml opencv-python\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["# set up environment\n","# comment out if not required\n","'''\n","!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install matplotlib numpy pandas pyyaml opencv-python\n","'''"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":259,"status":"ok","timestamp":1719456194851,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"VvSx-iP1P0Rx"},"outputs":[],"source":["# this cell is for downloading data.\n","# as of yet data is not hosted and is available in the private data folder\n","#!tar -xvzf data/imagenette2-320.tgz\n","#!unzip -qq data/imagenette2-320-processed.zip -d data/\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6732,"status":"ok","timestamp":1719456201569,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"BboU3GhFP0R1"},"outputs":[],"source":["# setup some imports\n","#custom imports\n","from common.transforms import ToTensor\n","from datautils.datareader import DataReader\n","from datautils.datareader import ImagenetteReader\n","from datautils.dataset import CustomDataset\n","from datautils.dataset import CustomImagenetDataset\n","from common.utils import get_exp_params, init_config, get_config, save2config, get_saved_model, get_modelinfo, get_model_data\n","from models.unet import UNet\n","from models.conv_net import ConvNet\n","from models.custom_models import get_model\n","\n","#py imports\n","import random\n","import numpy as np\n","import os\n","import torch\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from experiments.experiments import Experiment\n","from common.visualization import Visualization\n","from experiments.test_model import ModelTester"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62,"status":"ok","timestamp":1719456201570,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"NkWvKW0NP0R3","outputId":"a306c98d-4bd3-402a-bcc0-1c7bfdbbcce6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Config parameters\n","\n","{'X_key': 'L', 'data_dir': '/content/drive/MyDrive/Personal-Projects/Image-Colorization/data', 'device': 'cuda', 'output_dir': '/content/drive/MyDrive/Personal-Projects/Image-Colorization/output', 'root_dir': '/content/drive/MyDrive/Personal-Projects/Image-Colorization', 'use_gpu': True, 'y_key': 'AB'}\n"]}],"source":["# initialize directories and config data\n","init_config()\n","config = get_config()\n","print('Config parameters\\n')\n","print(config)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59,"status":"ok","timestamp":1719456201571,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"U3VbVcUUP0R2","outputId":"128fa8e0-0fe4-4f72-8960-409757406838"},"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment parameters\n","\n","{'transform': {'resize_dim': 256, 'crop_dim': 224}, 'train': {'shuffle_data': True, 'batch_size': 32, 'val_split_method': 'fixed-split', 'k': 3, 'val_percentage': 20, 'loss': 'l1', 'epoch_interval': 10, 'num_epochs': 1000}, 'model': {'name': 'conv_net', 'optimizer': 'Adam', 'lr': 0.0001, 'weight_decay': 1e-07, 'amsgrad': True, 'momentum': 0.8}, 'dataset': {'name': 'imagenette', 'size': 'subset'}, 'test_model': False}\n"]}],"source":["# read experiment parameters\n","exp_params = get_exp_params()\n","print('Experiment parameters\\n')\n","print(exp_params)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":57,"status":"ok","timestamp":1719456201573,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"moZyTdJtP0R4"},"outputs":[],"source":["#initialize randomness seed\n","seed = 123\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1734,"status":"ok","timestamp":1719456203251,"user":{"displayName":"Vinitra Muralikrishnan","userId":"14239738625620892639"},"user_tz":240},"id":"hyMh9b7qP0R4","outputId":"1f22d108-013a-45a6-de84-0bb7dad48cbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Full train dataset length: 9469\n","Test dataset length: 3925\n","Subset train dataset length: 94\n","Subset test dataset length: 39 \n","\n"]}],"source":["# read and load custom data\n","\n","#save X_key and y_key\n","save2config('X_key', 'L')\n","save2config('y_key', 'AB')\n","\n","if exp_params['dataset']['name'] == 'custom':\n","    #preprocess data or load preprocessed data (custom)\n","    dr = DataReader()\n","    ds = dr.get_split_data()\n","    Ltr, ABtr, ftr_len = ds['Ltr'], ds['ABtr'], ds['ftr_len']\n","    Lte, ABte, te_len = ds['Lte'], ds['ABte'], ds['te_len']\n","    print('Shape of X and y:', ds['Ltr'].shape, ds['ABtr'].shape)\n","\n","    #transform data\n","    composed_transforms =  transforms.Compose([\n","        ToTensor()\n","    ])\n","    #convert to dataset\n","    ftr_dataset = CustomDataset(Ltr, ABtr, ftr_len)\n","    te_dataset = CustomDataset(Lte, ABte, te_len)\n","    smlen = int(0.01 * len(ftr_dataset))\n","    smftr_dataset = torch.utils.data.Subset(ftr_dataset, list(range(smlen)))\n","    smftrte_dataset = torch.utils.data.Subset(ftr_dataset, list(range(10)))\n","    smtelen = int(0.1 * len(te_dataset))\n","    smfte_dataset = torch.utils.data.Subset(te_dataset, list(range(smtelen)))\n","    print('Full train dataset length:', len(ftr_dataset))\n","    print('Test dataset length:', len(te_dataset))\n","    print('Subset train dataset length:', smlen)\n","    print('Subset test dataset length:', smtelen, '\\n')\n","elif exp_params['dataset']['name'] == 'imagenette':\n","    dr = ImagenetteReader()\n","    train_paths, test_paths = dr.get_data_filepaths()\n","    ftr_dataset = CustomImagenetDataset(train_paths)\n","    te_dataset = CustomImagenetDataset(test_paths)\n","    smlen = int(0.01 * len(ftr_dataset))\n","    smftr_dataset = torch.utils.data.Subset(ftr_dataset, list(range(smlen)))\n","    smtelen = int(0.01 * len(te_dataset))\n","    smfte_dataset = torch.utils.data.Subset(te_dataset, list(range(smtelen)))\n","    smftrte_dataset = torch.utils.data.Subset(smftr_dataset, list(range(10)))\n","    print('Full train dataset length:', len(ftr_dataset))\n","    print('Test dataset length:', len(te_dataset))\n","    print('Subset train dataset length:', smlen)\n","    print('Subset test dataset length:', smtelen, '\\n')\n","else:\n","    raise SystemError('Invalid dataset name passed!')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"7YhIO8ZtFKuK","outputId":"0b621d41-b597-4645-e3b4-ecf6edc33661"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Running straight split\n","\tRunning Epoch 1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:09<00:00,  3.11s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\tEpoch 1 Training Loss: 0.15469925066358164\n","\tEpoch 1 Validation Loss: 0.112968310713768\n","\tRunning Epoch 10\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.59s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\tEpoch 10 Training Loss: 0.08770008228327099\n","\tEpoch 10 Validation Loss: 0.09824327379465103\n","\tRunning Epoch 20\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.57s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\tEpoch 20 Training Loss: 0.07906269595811241\n","\tEpoch 20 Validation Loss: 0.09311697632074356\n","\tRunning Epoch 30\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.52s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\tEpoch 30 Training Loss: 0.0759647523886279\n","\tEpoch 30 Validation Loss: 0.08483774214982986\n","\tRunning Epoch 40\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.61s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\tEpoch 40 Training Loss: 0.07373504732784472\n","\tEpoch 40 Validation Loss: 0.08604021370410919\n","\tRunning Epoch 50\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.57s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\tEpoch 50 Training Loss: 0.07260501972938839\n","\tEpoch 50 Validation Loss: 0.07901211827993393\n","\tRunning Epoch 60\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.56s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\tEpoch 60 Training Loss: 0.07108421192357414\n","\tEpoch 60 Validation Loss: 0.07830853760242462\n","\tRunning Epoch 70\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.62s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\tEpoch 70 Training Loss: 0.07037554014670222\n","\tEpoch 70 Validation Loss: 0.08112646639347076\n","\tRunning Epoch 80\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.60s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 80 Training Loss: 0.069692567775124\n","\tEpoch 80 Validation Loss: 0.07983627170324326\n","\tRunning Epoch 90\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.56s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 90 Training Loss: 0.06883730935422998\n","\tEpoch 90 Validation Loss: 0.08134128898382187\n","\tRunning Epoch 100\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.54s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 100 Training Loss: 0.0686263877310251\n","\tEpoch 100 Validation Loss: 0.07987377792596817\n","\tRunning Epoch 110\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.56s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 110 Training Loss: 0.0693853497505188\n","\tEpoch 110 Validation Loss: 0.07956290245056152\n","\tRunning Epoch 120\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.61s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 120 Training Loss: 0.06799202765289106\n","\tEpoch 120 Validation Loss: 0.07853581011295319\n","\tRunning Epoch 130\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.56s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 130 Training Loss: 0.06687798743185244\n","\tEpoch 130 Validation Loss: 0.08342545479536057\n","\tRunning Epoch 140\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.61s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 140 Training Loss: 0.06722422179422881\n","\tEpoch 140 Validation Loss: 0.07762564718723297\n","\tRunning Epoch 150\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.56s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 150 Training Loss: 0.06607049233035038\n","\tEpoch 150 Validation Loss: 0.07270849496126175\n","\tRunning Epoch 160\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.56s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 160 Training Loss: 0.06683204538728062\n","\tEpoch 160 Validation Loss: 0.07274273037910461\n","\tRunning Epoch 170\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.54s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 170 Training Loss: 0.06495271662348195\n","\tEpoch 170 Validation Loss: 0.07377227395772934\n","\tRunning Epoch 180\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.62s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 180 Training Loss: 0.06365177898030532\n","\tEpoch 180 Validation Loss: 0.07443930208683014\n","\tRunning Epoch 190\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.55s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 190 Training Loss: 0.06455679316269725\n","\tEpoch 190 Validation Loss: 0.08238706737756729\n","\tRunning Epoch 200\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.57s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 200 Training Loss: 0.062157952079647465\n","\tEpoch 200 Validation Loss: 0.07824258506298065\n","\tRunning Epoch 210\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.55s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 210 Training Loss: 0.062216200718754215\n","\tEpoch 210 Validation Loss: 0.0704599991440773\n","\tRunning Epoch 220\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.53s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 220 Training Loss: 0.06055816655096255\n","\tEpoch 220 Validation Loss: 0.08572322130203247\n","\tRunning Epoch 230\n"]},{"output_type":"stream","name":"stderr","text":["\t\tRunning through training set: 100%|██████████| 3/3 [00:07<00:00,  2.61s/it]\n","\t\tRunning through validation set: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tEpoch 230 Training Loss: 0.060397349298000336\n","\tEpoch 230 Validation Loss: 0.07687677443027496\n"]}],"source":["# model training\n","\n","if exp_params['dataset']['name'] == 'custom':\n","    if exp_params['dataset']['size'] == 'subset':\n","        #model training with small dataset (custom)\n","        exp = Experiment(exp_params[\"model\"][\"name\"], smftr_dataset)\n","        model_history = exp.train()\n","    else:\n","        #model training with full dataset (custom)\n","        exp = Experiment(exp_params[\"model\"][\"name\"], ftr_dataset)\n","        model_history = exp.train()\n","elif exp_params['dataset']['name'] == 'imagenette':\n","    if exp_params['dataset']['size'] == 'subset':\n","        #model training with small dataset (imagenette)\n","        composed_transforms =  transforms.Compose([\n","            #transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                        std=[0.229, 0.224, 0.225]),\n","            transforms.Resize(exp_params['transform']['resize_dim']),\n","            transforms.CenterCrop(exp_params['transform']['crop_dim'])\n","        ])\n","        exp = Experiment(exp_params[\"model\"][\"name\"], smftr_dataset, composed_transforms, 'imagenette')\n","        model_history = exp.train()\n","    else:\n","        #model training with full dataset (imagenette)\n","        composed_transforms =  transforms.Compose([\n","            #transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                        std=[0.229, 0.224, 0.225]),\n","            transforms.Resize(exp_params['transform']['resize_dim']),\n","            transforms.CenterCrop(exp_params['transform']['crop_dim'])\n","        ])\n","        exp = Experiment(exp_params[\"model\"][\"name\"], ftr_dataset, composed_transforms, 'imagenette')\n","        model_history = exp.train()\n","else:\n","    raise SystemError('Invalid dataset name passed!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZyTPPFH8FWOZ"},"outputs":[],"source":["# test model on validation set\n","\n","if exp_params['dataset']['name'] == 'custom' or exp_params['dataset']['name'] == 'imagenette':\n","    # get best model with custom dataset\n","    model, model_history, _ = get_model_data(exp_params[\"model\"][\"name\"])\n","    #model = get_saved_model(model, '')\n","    model_info = get_modelinfo('')\n","    print(\"\\nModel validation results\")\n","    #visualization results\n","    vis = Visualization(model_info, model_history)\n","    vis.get_results()\n","else:\n","    raise SystemError('Invalid dataset name passed!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G1Qr1SVCRuHh"},"outputs":[],"source":["# test fine-tuned model on training set\n","\n","if exp_params['dataset']['name'] == 'custom':\n","    #model testing with small subset of training dataset\n","    model = get_model(exp_params[\"model\"][\"name\"])\n","    model.load_state_dict(torch.load(\"models/checkpoints/last_model.pt\", map_location = torch.device(config[\"device\"])))\n","    print(\"\\n\\nTesting Saved Model on Training set subset\")\n","    mt = ModelTester(model, smftrte_dataset)\n","    mt.test_and_plot(ds[\"RGBtr\"], ABtr, \"best_model\", True)\n","elif exp_params['dataset']['name'] == 'imagenette':\n","    #model testing with small subset of training dataset (imagenette)\n","    composed_transforms =  transforms.Compose([\n","            #transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                        std=[0.229, 0.224, 0.225]),\n","            transforms.Resize(exp_params['transform']['resize_dim']),\n","            transforms.CenterCrop(exp_params['transform']['crop_dim'])\n","        ])\n","    model = get_model(exp_params[\"model\"][\"name\"])\n","    model.load_state_dict(torch.load(\"models/checkpoints/last_model.pt\", map_location = torch.device(config[\"device\"])))\n","    print(\"\\n\\nTesting Saved Model on subset of training set\")\n","    mt = ModelTester(model, smftrte_dataset, composed_transforms)\n","    mt.test_imagenette_and_plot(True)\n","else:\n","    raise SystemError('Invalid dataset name passed!')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPqmws5k2gD9"},"outputs":[],"source":["'''\n","# test fine-tuned model on test set\n","if exp_params['dataset']['name'] == 'custom':\n","    # model testing with small subset of training dataset\n","    model = get_model(exp_params[\"model\"][\"name\"])\n","    model.load_state_dict(torch.load(\"models/checkpoints/last_model.pt\", map_location = torch.device(config[\"device\"])))\n","    if exp_params['dataset']['size'] == 'subset':\n","        print(\"\\n\\nTesting Saved Model subset of test set\")\n","        mt = ModelTester(model, smfte_dataset)\n","        mt.test_and_plot(ds[\"RGBte\"], ABte, \"best_model\", True)\n","    else:\n","        print(\"\\n\\nTesting Saved Model on full test set\")\n","        mt = ModelTester(model, te_dataset)\n","        mt.test_and_plot(ds[\"RGBte\"], ABte, \"best_model\", True)\n","elif exp_params['dataset']['name'] == 'imagenette':\n","    # model testing with small subset of training dataset (imagenette)\n","    model = get_model(exp_params[\"model\"][\"name\"])\n","    model.load_state_dict(torch.load(\"models/checkpoints/last_model.pt\", map_location = torch.device(config[\"device\"])))\n","    if exp_params['dataset']['size'] == 'subset':\n","        print(\"\\n\\nTesting Saved Model on subset of test set\")\n","        mt = ModelTester(model, smfte_dataset, composed_transforms)\n","        mt.test_imagenette_and_plot(True)\n","    else:\n","        print(\"\\n\\nTesting Saved Model on full test set\")\n","        mt = ModelTester(model, te_dataset, composed_transforms)\n","        mt.test_imagenette_and_plot(True)\n","else:\n","    raise SystemError('Invalid dataset name passed!')\n","'''"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}